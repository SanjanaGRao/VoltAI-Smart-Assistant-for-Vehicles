{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# VoltAI: Smart Assistant for Your Vehicle\n",
        "\n",
        "Meet VoltAI, your intelligent assistant designed to keep your vehicle running smoothly and efficiently. Powered by Python, Pandas, and OpenAI's advanced language models, VoltAI brings real-time insights and smart decision-making right to your dashboard.\n",
        "\n",
        "With specialized agents like:\n",
        "\n",
        "- üöó Vehicle Health Analyst ‚Äì Monitors engine temperature, load, and overall performance.\n",
        "- üö® Alert Generator ‚Äì Instantly flags critical issues like low tire pressure or warning lights.\n",
        "- ‚õΩ Fuel Efficiency Advisor ‚Äì Tracks fuel trends to help you save money and go the distance.\n",
        "- üîß Maintenance Predictor ‚Äì Anticipates upcoming maintenance needs before problems arise.\n",
        "\n",
        "Just ask:\n",
        "\n",
        "‚ÄúIs my engine running hot today?‚Äù\n",
        "\n",
        "‚ÄúShould I schedule an oil change soon?‚Äù\n",
        "\n",
        "‚ÄúHow‚Äôs my tire pressure looking?‚Äù\n",
        "\n",
        "VoltAI turns raw vehicle data into real-time intelligence‚Äîso you can drive smarter, safer, and stress-free.\n",
        "\n",
        "Team 4 Members:\n",
        "- Abhijith Raj Urs Ravishankar\n",
        "- Harhshitha Banagalore Ramachandra\n",
        "- Sanjana Rao"
      ],
      "metadata": {
        "id": "DMd4uwXV4fn6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "c6a8Px7G32DQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc3a3b46-f145-4657-f59a-33772658fe59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.70.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.9)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.5)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.45.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# üöÄ Installing CrewAI, LangChain, OpenAI, and additional tools/libraries quietly...\n",
        "!pip install -q crewai langchain langchain-openai openai crewai-tools ipython\n",
        "!pip install 'crewai[tools]'"
      ],
      "metadata": {
        "id": "wlKbakHLJROb"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load OpenAI API key from Colab userdata secrets\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "# Set default OpenAI model for CrewAI agents\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-4o'\n",
        "\n",
        "# Confirmation message\n",
        "print(\"‚úÖ OpenAI key, Gemini Key and model are successfully configured.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OTEeskLJZpm",
        "outputId": "3d567462-6648-43ea-a94f-7d9f67ef1d2f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ OpenAI key, Gemini Key and model are successfully configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai gradio pandas\n",
        "\n",
        "import pandas as pd\n",
        "import openai\n",
        "import gradio as gr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b0F7HP9Jf0Y",
        "outputId": "8f411cd8-f82c-47ee-cfe0-707fd2c1b202"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.70.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.25.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.9)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.5)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.45.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload a file manually or handle from other sources in future\n",
        "uploaded_df = None\n",
        "\n",
        "def load_data_from_file(file_obj):\n",
        "    global uploaded_df\n",
        "    uploaded_df = pd.read_csv(file_obj.name)\n",
        "    return \"‚úÖ File uploaded and data loaded!\"\n",
        "# To load from Google Drive or API\n",
        "# df = pd.read_csv(\"https://drive.google.com/uc?id=<file_id>\")\n",
        "# or df = requests.get(\"your_api_url\").json()"
      ],
      "metadata": {
        "id": "6Zo5Fh7lMbtA"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_engine_temperature(temp):\n",
        "    if temp > 100:\n",
        "        return \"‚ö†Ô∏è High engine temperature! Immediate attention needed.\"\n",
        "    elif temp < 70:\n",
        "        return \"‚ö†Ô∏è Engine temperature lower than usual. Check cooling system.\"\n",
        "    return \"‚úÖ Engine temperature is normal.\"\n",
        "\n",
        "def check_oil_level(oil_level):\n",
        "    return \"‚ö†Ô∏è Oil level is low. Consider an oil change.\" if oil_level < 50 else \"‚úÖ Oil level is good.\"\n",
        "\n",
        "def check_fuel_level(fuel_level):\n",
        "    return \"‚ö†Ô∏è Low fuel level. Please refill soon.\" if fuel_level < 25 else \"‚úÖ Fuel level is sufficient.\"\n",
        "\n",
        "def check_tire_pressure(row):\n",
        "    alerts = []\n",
        "    for tire in ['tire_pressure_FL', 'tire_pressure_FR', 'tire_pressure_RL', 'tire_pressure_RR']:\n",
        "        if row[tire] < 30:\n",
        "            alerts.append(f\"‚ö†Ô∏è Low pressure in {tire[-2:]} tire.\")\n",
        "    return alerts if alerts else [\"‚úÖ All tire pressures are within normal range.\"]\n",
        "\n",
        "def check_engine_light(light_on):\n",
        "    return \"‚ö†Ô∏è Check engine light is ON.\" if light_on else \"‚úÖ No engine warning lights.\""
      ],
      "metadata": {
        "id": "7_2KmM9NMnZU"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagnostic summary using last entry\n",
        "import openai\n",
        "\n",
        "# New SDK: create OpenAI client\n",
        "client = openai.OpenAI()\n",
        "\n",
        "def generate_vehicle_summary(vehicle_id, df):\n",
        "    try:\n",
        "        if df is None or df.empty:\n",
        "            return \"‚ùå Please upload data first.\"\n",
        "\n",
        "        if vehicle_id not in df['vehicle_id'].unique():\n",
        "            return f\"‚ùå Vehicle ID '{vehicle_id}' not found in data.\"\n",
        "\n",
        "        latest = df[df['vehicle_id'] == vehicle_id].sort_values(\"tracking_timestamp\").iloc[-1]\n",
        "\n",
        "        checks = (\n",
        "            f\"üîß Vehicle Diagnostic Summary\\n\"\n",
        "            f\"- Engine Temp: {latest['temp_engine_C']} ¬∞C\\n\"\n",
        "            f\"- Fuel Level: {latest['fuel_level_percent']} %\\n\"\n",
        "            f\"- Tire Pressure FL: {latest['tire_pressure_FL']} psi\\n\"\n",
        "            f\"- Tire Pressure FR: {latest['tire_pressure_FR']} psi\\n\"\n",
        "            f\"- Tire Pressure RL: {latest['tire_pressure_RL']} psi\\n\"\n",
        "            f\"- Tire Pressure RR: {latest['tire_pressure_RR']} psi\\n\"\n",
        "            f\"- Timestamp: {latest['tracking_timestamp']}\"\n",
        "        )\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        You are an expert car advisor. A user has the following vehicle status:\n",
        "\n",
        "        {checks}\n",
        "\n",
        "        Please summarize what this means in simple words.\n",
        "        \"\"\"\n",
        "\n",
        "        # ‚úÖ New SDK call\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "\n",
        "        ai_summary = response.choices[0].message.content.strip()\n",
        "\n",
        "        return f\"{checks}\\n\\nü§ñ AI Summary:\\n{ai_summary}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Internal error: {str(e)}\"\n",
        "\n"
      ],
      "metadata": {
        "id": "2j20Xte8Mu-i"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI()\n",
        "\n",
        "def query_vehicle_data(user_query, df):\n",
        "    try:\n",
        "        if df is None or df.empty:\n",
        "            return \"‚ùå Please upload the vehicle data first.\"\n",
        "\n",
        "        sample_data = df.tail(5).to_csv(index=False)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        You are an expert vehicle data analyst. Here's the recent sensor data from a car:\n",
        "\n",
        "        {sample_data}\n",
        "\n",
        "        Now answer the user's question: \"{user_query}\"\n",
        "        \"\"\"\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",  # or gpt-3.5-turbo\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Internal error: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "ZAci2lntMySI"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from crewai import Crew, Agent, Task, Process, LLM\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import Tool as LangchainTool # Import Tool from langchain and rename to avoid conflict\n",
        "import os\n",
        "import gradio as gr\n",
        "import openai\n",
        "import google.generativeai as genai\n",
        "from dotenv import load_dotenv\n",
        "from langchain.tools import tool\n",
        "from IPython.display import display, Markdown\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = LLM(model=\"gpt-4o\")\n",
        "\n",
        "@tool\n",
        "def ask_about_specific_vehicle(vehicle_id: str, question: str, df: pd.DataFrame) -> str:\n",
        "    \"\"\"Query OpenAI about a specific vehicle ID using its data only.\"\"\"\n",
        "\n",
        "    vehicle_row = df[df['vehicle_id'] == vehicle_id]\n",
        "\n",
        "    if vehicle_row.empty:\n",
        "        return f\"‚ùå Vehicle ID {vehicle_id} not found in the dataset.\"\n",
        "\n",
        "    vehicle_data_str = vehicle_row.to_string(index=False)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a smart vehicle diagnostic assistant.\n",
        "\n",
        "You are analyzing the following data for a single vehicle (Vehicle ID: {vehicle_id}):\n",
        "{vehicle_data_str}\n",
        "\n",
        "Now answer this question based ONLY on that vehicle's data:\n",
        "\n",
        "{question}\n",
        "\n",
        "Be specific and detailed. Act like a skilled mechanic. For example:\n",
        "- If the question is about oil level, mention the percentage and give a clear recommendation.\n",
        "- If it's about tire pressure, mention each tire's pressure and suggest adjustments.\n",
        "- If it's about engine temperature, mention the exact temperature and suggest precautions.\n",
        "- If it's about fuel level, mention the percentage and suggest refueling if needed.\n",
        "- If it's about engine load, mention the percentage and suggest driving style adjustments.\n",
        "- If it's about air pressure, mention the pressure and suggest checking for leaks.\n",
        "- If it's about check engine light, say whether it's on and possible reasons.\n",
        "- Avoid listing all columns or sounding generic. Be a helpful expert mechanic!\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a precise and helpful vehicle assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return response['choices'][0]['message']['content'].strip()\n",
        "    except Exception as e:\n",
        "        return f\"OpenAI Error: {str(e)}\"\n",
        "\n",
        "# Define Agents\n",
        "vehicle_health_analyst = Agent(\n",
        "    role='Vehicle Health Analyst',\n",
        "    goal='Analyze vehicle data to determine health status and detect anomalies.',\n",
        "    backstory='An expert in automotive diagnostics with deep knowledge of onboard telemetry systems.',\n",
        "    verbose=True,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "alert_generator = Agent(\n",
        "    role='Alert Generator',\n",
        "    goal='Generate actionable alerts based on anomalies or threshold breaches in vehicle data.',\n",
        "    backstory='A seasoned system monitor designed to notify users in real-time about potential issues.',\n",
        "    verbose=True,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "fuel_efficiency_advisor = Agent(\n",
        "    role='Fuel Efficiency Advisor',\n",
        "    goal='Evaluate driving and engine metrics to provide suggestions for better fuel efficiency.',\n",
        "    backstory='A fuel economist with insights on optimizing engine performance and driving behavior.',\n",
        "    verbose=True,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "maintenance_predictor = Agent(\n",
        "    role='Maintenance Predictor',\n",
        "    goal='Predict upcoming vehicle maintenance needs using past data and operational trends.',\n",
        "    backstory='A predictive maintenance AI trained on thousands of fleet vehicle histories.',\n",
        "    verbose=True,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# 1Ô∏è‚É£ Task for the Vehicle Health Analyst agent\n",
        "health_analysis_task = Task(\n",
        "    description=(\n",
        "        \"Analyze the vehicle's recent telemetry data including engine temperature, oil level, tire pressure, speed, and engine load. \"\n",
        "        \"Detect any abnormal readings or potential early signs of failure.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A concise diagnostic summary highlighting vehicle health, including any unusual patterns or values that need attention.\"\n",
        "    ),\n",
        "    agent=vehicle_health_analyst\n",
        ")\n",
        "\n",
        "# 2Ô∏è‚É£ Task for the Alert agent\n",
        "alert_task = Task(\n",
        "    description=(\n",
        "        \"Review the diagnostic data and identify any urgent issues such as high engine temperature, low tire pressure, \"\n",
        "        \"critical oil levels, or check engine light status. Generate warnings or alerts if thresholds are breached.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A list of alerts with descriptions and severity levels, highlighting the issues that require immediate driver attention.\"\n",
        "    ),\n",
        "    agent=alert_generator\n",
        ")\n",
        "\n",
        "# 3Ô∏è‚É£ Task for the Fuel Efficieny agent\n",
        "fuel_efficiency_task = Task(\n",
        "    description=(\n",
        "        \"Assess the vehicle's average speed, fuel level trends, and engine load to estimate fuel efficiency. \"\n",
        "        \"Recommend ways the driver can improve mileage and reduce fuel consumption.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A breakdown of fuel efficiency metrics and clear tips for improving mileage based on current driving patterns.\"\n",
        "    ),\n",
        "    agent=fuel_efficiency_advisor\n",
        ")\n",
        "\n",
        "# 4Ô∏è‚É£  Task for the Maintainence Prediction agent\n",
        "maintenance_prediction_task = Task(\n",
        "    description=(\n",
        "        \"Analyze the vehicle‚Äôs usage patterns, odometer readings, oil levels, and historical trends to predict upcoming maintenance needs. \"\n",
        "        \"Estimate when the next oil change, tire rotation, or other maintenance is due.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"Maintenance forecast including estimated due dates for key services like oil changes or tire care.\"\n",
        "    ),\n",
        "    agent=maintenance_predictor\n",
        ")\n"
      ],
      "metadata": {
        "id": "MoOIvwfEeH5B"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ### Crew Creation and Execution Cell\n",
        "# # This cell creates a Crew with all defined agents and tasks, executes the crew,\n",
        "# # and then displays the final recommendation in a nicely formatted Markdown cell.\n",
        "def respond_to_vehicle_query1(vehicle_id, user_question, df):\n",
        "    \"\"\"Process a vehicle query using CrewAI workflow with fixed tool validation\"\"\"\n",
        "    # Input validation\n",
        "    if df is None or df.empty:\n",
        "        return \"‚ùå Please upload vehicle data first.\"\n",
        "\n",
        "    if vehicle_id not in df['vehicle_id'].unique():\n",
        "        return f\"‚ùå Vehicle ID '{vehicle_id}' not found in data.\"\n",
        "\n",
        "    try:\n",
        "        # Create a single tool that handles the vehicle query\n",
        "        # Important: Use proper Langchain tool format\n",
        "        from langchain.tools import BaseTool\n",
        "        from typing import Any, Optional\n",
        "\n",
        "        class VehicleDataTool(BaseTool):\n",
        "            name: str = \"vehicle_data_tool\"  # Add type annotation\n",
        "            description: str = \"Get data about the specified vehicle\"  # Add type annotation\n",
        "            return_direct: bool = False  # Add type annotation\n",
        "\n",
        "            def _run(self, query: str) -> str:\n",
        "                vehicle_row = df[df['vehicle_id'] == vehicle_id]\n",
        "                return vehicle_row.to_string(index=False)\n",
        "\n",
        "            async def _arun(self, query: str) -> str:\n",
        "                raise NotImplementedError(\"This tool does not support async\")\n",
        "\n",
        "        # Create proper tool instances\n",
        "        vehicle_tool = VehicleDataTool()\n",
        "\n",
        "        # Create the agents with properly defined tools\n",
        "        vehicle_specialist = Agent(\n",
        "            role=vehicle_health_analyst.role,\n",
        "            goal=vehicle_health_analyst.goal,\n",
        "            backstory=f\"{vehicle_health_analyst.backstory} Currently analyzing vehicle {vehicle_id} to answer: {user_question}\",\n",
        "            llm=llm,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        alert_specialist = Agent(\n",
        "            role=alert_generator.role,\n",
        "            goal=alert_generator.goal,\n",
        "            backstory=f\"{alert_generator.backstory} Currently analyzing vehicle {vehicle_id} to answer: {user_question}\",\n",
        "            llm=llm,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        fuel_specialist = Agent(\n",
        "            role=fuel_efficiency_advisor.role,\n",
        "            goal=fuel_efficiency_advisor.goal,\n",
        "            backstory=f\"{fuel_efficiency_advisor.backstory} Currently analyzing vehicle {vehicle_id} to answer: {user_question}\",\n",
        "            llm=llm,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        maintenance_specialist = Agent(\n",
        "            role=maintenance_predictor.role,\n",
        "            goal=maintenance_predictor.goal,\n",
        "            backstory=f\"{maintenance_predictor.backstory} Currently analyzing vehicle {vehicle_id} to answer: {user_question}\",\n",
        "            llm=llm,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        # Create tasks with context added to the descriptions\n",
        "        task1 = Task(\n",
        "            description=f\"Analyze vehicle {vehicle_id} data to answer: '{user_question}'. Examine engine temperature, oil level, tire pressure, speed, and engine load.\",\n",
        "            expected_output=\"A detailed diagnostic summary answering the user's question.\",\n",
        "            agent=vehicle_specialist\n",
        "        )\n",
        "\n",
        "        task2 = Task(\n",
        "            description=f\"For vehicle {vehicle_id}, identify any urgent issues or warnings related to the question: '{user_question}'.\",\n",
        "            expected_output=\"A list of alerts with severity levels relevant to the user's question.\",\n",
        "            agent=alert_specialist\n",
        "        )\n",
        "\n",
        "        task3 = Task(\n",
        "            description=f\"Evaluate the fuel efficiency metrics for vehicle {vehicle_id} in relation to: '{user_question}'.\",\n",
        "            expected_output=\"Fuel efficiency insights and recommendations relevant to the question.\",\n",
        "            agent=fuel_specialist\n",
        "        )\n",
        "\n",
        "        task4 = Task(\n",
        "            description=f\"Predict maintenance needs for vehicle {vehicle_id} based on the data and question: '{user_question}'.\",\n",
        "            expected_output=\"Maintenance timeline and recommendations addressing the user's question.\",\n",
        "            agent=maintenance_specialist\n",
        "        )\n",
        "\n",
        "        # Create the crew with all agents and tasks\n",
        "        crew = Crew(\n",
        "            agents=[\n",
        "                vehicle_specialist,\n",
        "                alert_specialist,\n",
        "                fuel_specialist,\n",
        "                maintenance_specialist\n",
        "            ],\n",
        "            tasks=[task1, task2, task3, task4],\n",
        "            verbose=False,\n",
        "            process=Process.sequential\n",
        "        )\n",
        "\n",
        "        # Run the crew and return results\n",
        "        result = crew.kickoff()\n",
        "        return result.raw\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        error_details = traceback.format_exc()\n",
        "        return f\"‚ùå Error: {str(e)}\\n\\nDetails: {error_details}\""
      ],
      "metadata": {
        "id": "n7JZf_Bkm4Lc"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import geocoder\n",
        "import requests\n",
        "import asyncio\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --------- Data Functions ---------\n",
        "global_df = pd.DataFrame()\n",
        "\n",
        "def load_data_from_file(file):\n",
        "    try:\n",
        "        df = pd.read_csv(file.name)\n",
        "        return \"‚úÖ File uploaded successfully.\", df\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {e}\", None\n",
        "\n",
        "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")  # Make sure you set this securely\n",
        "\n",
        "def get_today_weather_advice():\n",
        "    # 1. Get current location\n",
        "    g = geocoder.ip(\"me\")\n",
        "    if not g.ok:\n",
        "        return \"‚ùå Failed to detect location.\"\n",
        "\n",
        "    latitude, longitude = g.latlng\n",
        "    city, country = g.city, g.country\n",
        "\n",
        "    # 2. Get today's weather from Open-Meteo\n",
        "    weather_url = \"https://api.open-meteo.com/v1/forecast\"\n",
        "    params = {\n",
        "        \"latitude\": latitude,\n",
        "        \"longitude\": longitude,\n",
        "        \"daily\": \"temperature_2m_max,temperature_2m_min,precipitation_sum\",\n",
        "        \"timezone\": \"auto\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(weather_url, params=params)\n",
        "    if response.status_code != 200:\n",
        "        return \"‚ùå Weather data fetch failed.\"\n",
        "\n",
        "    data = response.json()\n",
        "    today_index = 0\n",
        "    date = data[\"daily\"][\"time\"][today_index]\n",
        "    max_temp = data[\"daily\"][\"temperature_2m_max\"][today_index]\n",
        "    min_temp = data[\"daily\"][\"temperature_2m_min\"][today_index]\n",
        "    precipitation = data[\"daily\"][\"precipitation_sum\"][today_index]\n",
        "\n",
        "    # 3. Format prompt for Gemini\n",
        "    weather_summary = (\n",
        "        f\"Today's weather for a vehicle in {city}, {country} on {date}:\\n\"\n",
        "        f\"- Max Temp: {max_temp}¬∞C\\n\"\n",
        "        f\"- Min Temp: {min_temp}¬∞C\\n\"\n",
        "        f\"- Precipitation: {precipitation}mm\\n\\n\"\n",
        "        \"As an AI vehicle assistant, You are an expert vehicle assistant. Give concise, smart driving and maintenance advice \"\n",
        "        \"for a driver based on this forecast. This is not an EV Vehicle! Format the responses well.\"\n",
        "    )\n",
        "\n",
        "    # 4. Send to Gemini API\n",
        "    gemini_url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    payload = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"parts\": [{\"text\": weather_summary}]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    gemini_response = requests.post(gemini_url, headers=headers, json=payload)\n",
        "\n",
        "    if gemini_response.status_code != 200:\n",
        "        return f\"‚ùå Gemini API Error: {gemini_response.text}\"\n",
        "\n",
        "    advice = gemini_response.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "\n",
        "    # 5. Return final result\n",
        "    return f\"üìç {city}, {country} ‚Äî {date}\\nüå° Max: {max_temp}¬∞C | Min: {min_temp}¬∞C\\n‚òî Precip: {precipitation}mm\\n\\nü§ñ Friendly Advice:\\n{advice}\"\n",
        "\n",
        "# --------- Dashboard Summary ---------\n",
        "def auto_refresh_dashboard(vehicle_id, df):\n",
        "    if df is None or df.empty:\n",
        "        return \"‚ùå Please upload data first.\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
        "\n",
        "    if vehicle_id not in df[\"vehicle_id\"].unique():\n",
        "        return f\"‚ùå Vehicle ID '{vehicle_id}' not found.\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
        "\n",
        "    filtered = df[df[\"vehicle_id\"] == vehicle_id].copy()\n",
        "    filtered[\"tracking_timestamp\"] = pd.to_datetime(filtered[\"tracking_timestamp\"], dayfirst=True, errors=\"coerce\")\n",
        "    filtered = filtered.dropna(subset=[\"tracking_timestamp\"])\n",
        "\n",
        "    for col in [\n",
        "        \"engine_load_percent\", \"avg_speed_kmph\", \"temp_engine_C\", \"fuel_level_percent\",\n",
        "        \"tire_pressure_FL\", \"tire_pressure_FR\", \"tire_pressure_RL\", \"tire_pressure_RR\"\n",
        "    ]:\n",
        "        filtered[col] = pd.to_numeric(filtered[col], errors=\"coerce\")\n",
        "\n",
        "    filtered = filtered.dropna()\n",
        "    latest = filtered.iloc[-1]\n",
        "\n",
        "    temp = f\"{latest.get('temp_engine_C', 'N/A')} ¬∞C\"\n",
        "    fuel = f\"{latest.get('fuel_level_percent', 'N/A')} %\"\n",
        "    tire_fl = f\"{latest.get('tire_pressure_FL', 'N/A')} psi\"\n",
        "    tire_fr = f\"{latest.get('tire_pressure_FR', 'N/A')} psi\"\n",
        "    tire_rl = f\"{latest.get('tire_pressure_RL', 'N/A')} psi\"\n",
        "    tire_rr = f\"{latest.get('tire_pressure_RR', 'N/A')} psi\"\n",
        "\n",
        "    return f\"‚úÖ Live data for {vehicle_id}\", temp, fuel, tire_fl, tire_fr, tire_rl, tire_rr\n",
        "\n",
        "# --------- Chart 1: Tyre Pressure ---------\n",
        "def plot_avg_tire_pressure(df):\n",
        "    try:\n",
        "        tires = [\"tire_pressure_FL\", \"tire_pressure_FR\", \"tire_pressure_RL\", \"tire_pressure_RR\"]\n",
        "        df[tires] = df[tires].apply(pd.to_numeric, errors=\"coerce\")\n",
        "        avg_pressures = df[tires].mean()\n",
        "\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        avg_pressures.plot(kind=\"bar\", color=\"skyblue\")\n",
        "        plt.title(\"Average Tyre Pressure\")\n",
        "        plt.ylabel(\"PSI\")\n",
        "        plt.xticks(rotation=0)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        path = \"avg_tire_pressure_bar.png\"\n",
        "        plt.savefig(path, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "        return gr.update(value=path)\n",
        "    except Exception as e:\n",
        "        return gr.update(value=None, label=f\"‚ùå Bar Chart Error: {e}\")\n",
        "\n",
        "# --------- Chart 2: Engine Load vs Speed Line ---------\n",
        "def plot_engine_vs_speed(df):\n",
        "    try:\n",
        "        df[\"tracking_timestamp\"] = pd.to_datetime(df[\"tracking_timestamp\"], dayfirst=True, errors=\"coerce\")\n",
        "        df[\"engine_load_percent\"] = pd.to_numeric(df[\"engine_load_percent\"], errors=\"coerce\")\n",
        "        df[\"avg_speed_kmph\"] = pd.to_numeric(df[\"avg_speed_kmph\"], errors=\"coerce\")\n",
        "\n",
        "        df = df.dropna(subset=[\"tracking_timestamp\", \"engine_load_percent\", \"avg_speed_kmph\"])\n",
        "        df = df.sort_values(\"tracking_timestamp\")\n",
        "\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(df[\"tracking_timestamp\"], df[\"engine_load_percent\"], label=\"Engine Load (%)\", linewidth=2)\n",
        "        plt.plot(df[\"tracking_timestamp\"], df[\"avg_speed_kmph\"], label=\"Average Speed (km/h)\", linewidth=2)\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Value\")\n",
        "        plt.title(\"Engine Load vs. Average Speed Over Time\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        path = \"engine_vs_speed_linechart.png\"\n",
        "        plt.savefig(path, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "        return gr.update(value=path)\n",
        "    except Exception as e:\n",
        "        return gr.update(value=None, label=f\"‚ùå Line Chart Error: {e}\")\n",
        "\n",
        "# --------- Chart 3: Vehicle Health Overview (Area Chart) ---------\n",
        "def plot_vehicle_health_area(df):\n",
        "    try:\n",
        "        df[\"tracking_timestamp\"] = pd.to_datetime(df[\"tracking_timestamp\"], dayfirst=True, errors=\"coerce\")\n",
        "        for col in [\"temp_engine_C\", \"fuel_level_percent\", \"engine_load_percent\"]:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "        df = df.dropna(subset=[\"tracking_timestamp\", \"temp_engine_C\", \"fuel_level_percent\", \"engine_load_percent\"])\n",
        "        df = df.set_index(\"tracking_timestamp\").sort_index()\n",
        "\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.stackplot(\n",
        "            df.index,\n",
        "            df[\"temp_engine_C\"],\n",
        "            df[\"fuel_level_percent\"],\n",
        "            df[\"engine_load_percent\"],\n",
        "            labels=[\"Engine Temp (¬∞C)\", \"Fuel Level (%)\", \"Engine Load (%)\"],\n",
        "            alpha=0.85\n",
        "        )\n",
        "        plt.legend(loc=\"upper right\")\n",
        "        plt.title(\"Vehicle Health Overview Over Time\")\n",
        "        plt.ylabel(\"Sensor Value\")\n",
        "        plt.xlabel(\"Date\")\n",
        "        plt.tight_layout()\n",
        "\n",
        "        path = \"vehicle_health_area_chart.png\"\n",
        "        plt.savefig(path, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "        return gr.update(value=path)\n",
        "    except Exception as e:\n",
        "        return gr.update(value=None, label=f\"‚ùå Area Chart Error: {e}\")\n",
        "# --------- Gradio Interface ---------\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üöó VoltAI: Smart Vehicle Assistant\")\n",
        "\n",
        "    df_state = gr.State()\n",
        "\n",
        "    with gr.Tab(\"üîß Diagnostics & Upload\"):\n",
        "        with gr.Row():\n",
        "            file_input = gr.File(label=\"Upload vehicle_data.csv\")\n",
        "            upload_output = gr.Textbox(label=\"Upload Status\")\n",
        "        file_input.change(fn=load_data_from_file, inputs=file_input, outputs=[upload_output, df_state])\n",
        "\n",
        "        with gr.Row():\n",
        "            vehicle_id_input = gr.Textbox(label=\"Enter Vehicle ID\")\n",
        "            diagnose_btn = gr.Button(\"Run Diagnostic\")\n",
        "            diagnosis_output = gr.Textbox(label=\"Diagnosis Summary\", lines=6)\n",
        "\n",
        "        diagnose_btn.click(fn=generate_vehicle_summary, inputs=[vehicle_id_input, df_state], outputs=diagnosis_output)\n",
        "\n",
        "    with gr.Tab(\"‚ùì Ask About Data\"):\n",
        "      with gr.Row():\n",
        "        vehicle_id_input = gr.Textbox(label=\"Vehicle ID (e.g., VH200001)\")\n",
        "        question_input = gr.Textbox(label=\"Ask a question about recent data\")\n",
        "        ask_btn = gr.Button(\"Ask\")\n",
        "        answer_output = gr.Textbox(label=\"AI Answer\", lines=8)\n",
        "      # This is the critical part - make sure the inputs and outputs match your function\n",
        "      ask_btn.click(\n",
        "        fn=respond_to_vehicle_query1,\n",
        "        inputs=[vehicle_id_input, question_input, df_state],  # Make sure df_state is passed as the third argument\n",
        "        outputs=answer_output)\n",
        "\n",
        "    with gr.Tab(\"üå¶Ô∏è Weather-Based Advice\"):\n",
        "        weather_btn = gr.Button(\"Get Today's Vehicle Weather Advice\")\n",
        "        weather_output = gr.Textbox(label=\"Weather + Advice\", lines=10)\n",
        "        weather_btn.click(fn=get_today_weather_advice, outputs=weather_output)\n",
        "\n",
        "    with gr.Tab(\"üìä Live Vehicle Dashboard\"):\n",
        "        live_id = gr.Textbox(label=\"Vehicle ID for Live Monitoring\")\n",
        "        refresh_btn = gr.Button(\"Refresh Now\")\n",
        "        live_status = gr.Textbox(label=\"Live Status\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                temp = gr.Textbox(label=\"Engine Temp\")\n",
        "                fuel = gr.Textbox(label=\"Fuel Level\")\n",
        "            with gr.Column():\n",
        "                tire_fl = gr.Textbox(label=\"Tyre Pressure - Front Left\")\n",
        "                tire_fr = gr.Textbox(label=\"Tyre Pressure - Front Right\")\n",
        "                tire_rl = gr.Textbox(label=\"Tyre Pressure - Rear Left\")\n",
        "                tire_rr = gr.Textbox(label=\"Tyre Pressure - Rear Right\")\n",
        "\n",
        "        with gr.Row():\n",
        "          weather_btn = gr.Button(\"Get Today's Vehicle Weather Advice\")\n",
        "          weather_output = gr.Textbox(label=\"Weather + Advice\", lines=10)\n",
        "          weather_btn.click(fn=get_today_weather_advice, outputs=weather_output)\n",
        "\n",
        "        with gr.Row():\n",
        "          vehicle_id_input = gr.Textbox(label=\"Vehicle ID (e.g., VH200001)\")\n",
        "          question_input = gr.Textbox(label=\"Ask a question about recent data\")\n",
        "          ask_btn = gr.Button(\"Ask\")\n",
        "          answer_output = gr.Textbox(label=\"AI Answer\", lines=8)\n",
        "        # This is the critical part - make sure the inputs and outputs match your function\n",
        "        ask_btn.click(\n",
        "          fn=respond_to_vehicle_query1,\n",
        "          inputs=[vehicle_id_input, question_input, df_state],  # Make sure df_state is passed as the third argument\n",
        "          outputs=answer_output)\n",
        "\n",
        "        refresh_btn.click(\n",
        "            fn=auto_refresh_dashboard,\n",
        "            inputs=[live_id, df_state],\n",
        "            outputs=[live_status, temp, fuel, tire_fl, tire_fr, tire_rl, tire_rr]\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            show_bar = gr.Button(\"üìä Avg Tyre Pressure\")\n",
        "            show_line = gr.Button(\"üìà Engine Load vs Speed\")\n",
        "            show_area = gr.Button(\"üß† Vehicle Health Overview\")\n",
        "\n",
        "        with gr.Row():\n",
        "            bar_out = gr.Image(label=\"Bar Chart\", type=\"filepath\")\n",
        "            line_out = gr.Image(label=\"Line Chart\", type=\"filepath\")\n",
        "            area_out = gr.Image(label=\"Health Overview\", type=\"filepath\")\n",
        "\n",
        "        show_bar.click(fn=plot_avg_tire_pressure, inputs=df_state, outputs=bar_out)\n",
        "        show_line.click(fn=plot_engine_vs_speed, inputs=df_state, outputs=line_out)\n",
        "        show_area.click(fn=plot_vehicle_health_area, inputs=df_state, outputs=area_out)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "8jpveq0fVdft",
        "outputId": "12cb0ec6-47f4-4327-e32e-c7025136ae58"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9805d71a266a1c861c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9805d71a266a1c861c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OOeVjq8_Ge8M"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}